{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK_sdwfHwudy"
      },
      "source": [
        "## Phase-3: Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFEz_Q2-w2BK"
      },
      "source": [
        "Step-0a: Data Ingestion and Initial Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex2zGWivwY93",
        "outputId": "f1d727ad-be23-49c4-9e54-d43b6a6b7edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/multimodal_mammography\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Go to your project folder\n",
        "%cd /content/drive/MyDrive/multimodal_mammography\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9M5-HwkUw5Cq"
      },
      "outputs": [],
      "source": [
        "import importlib.util\n",
        "\n",
        "def load_module_from_path(name, path):\n",
        "    spec = importlib.util.spec_from_file_location(name, path)\n",
        "    module = importlib.util.module_from_spec(spec)\n",
        "    spec.loader.exec_module(module)\n",
        "    return module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocI2-hsKxC8C",
        "outputId": "49d37253-d239-4327-bc8c-8b3495aa47ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Detected Google Colab environment.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive mounted.\n",
            "üì¶ Installing required packages...\n",
            "‚úÖ Dependencies installed.\n",
            " Warnings suppressed.\n",
            "üîÅ Seed set to 42\n",
            " Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Load environment setup\n",
        "env = load_module_from_path(\"env\", \"setup/environment.py\")\n",
        "install = load_module_from_path(\"install\", \"setup/install_colab.py\")\n",
        "_ = load_module_from_path(\"imports\", \"setup/imports.py\")  # No functions to call\n",
        "\n",
        "# Run setup\n",
        "install.install_dependencies()\n",
        "env.suppress_warnings()\n",
        "env.set_seed(42)\n",
        "device = env.get_device()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0psAZT1xJF-"
      },
      "source": [
        "Step-0b: Loading Required csvs' and extracting/exploring images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUBNcL-wxEi_"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Load the dynamic module\n",
        "data_loader = load_module_from_path(\"data_loader\", \"data/load_data.py\")\n",
        "\n",
        "# ‚úÖ Correct CSV paths\n",
        "metadata_path    = \"/content/drive/MyDrive/multimodal_mammography/dataset/csv/metadata.csv\"\n",
        "breast_anno_path = \"/content/drive/MyDrive/multimodal_mammography/dataset/csv/breast-level_annotations.csv\"\n",
        "finding_anno_path = \"/content/drive/MyDrive/multimodal_mammography/dataset/csv/finding_annotations.csv\"\n",
        "\n",
        "# ‚úÖ Load and view data\n",
        "metadata_df, breast_df, finding_df = data_loader.load_mammo_data(\n",
        "    metadata_path,\n",
        "    breast_anno_path,\n",
        "    finding_anno_path,\n",
        "    verbose=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPooQpAxLC-f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "image_df=pd.read_csv(\"/content/drive/MyDrive/multimodal_mammography/dataset/csv/image_df_upsampled_studywise.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L5ZMlAgLc1X",
        "outputId": "d3ea25f5-9e75-4d00-86b7-ba69ca0bb039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['image_id', 'study_id', 'filename', 'birads', 'birads_dir', 'density',\n",
            "       'laterality', 'view_position', 'split', 'finding_categories',\n",
            "       'finding_birads_clean', 'xmin', 'ymin', 'xmax', 'ymax', 'has_bbox',\n",
            "       'age', 'birads_binary', 'birads_cleaned', 'birads_study_level',\n",
            "       'finding_mass', 'finding_suspicious_calcification',\n",
            "       'finding_focal_asymmetry', 'finding_asymmetry',\n",
            "       'finding_global_asymmetry', 'finding_architectural_distortion',\n",
            "       'finding_skin_thickening', 'finding_skin_retraction',\n",
            "       'finding_nipple_retraction', 'finding_suspicious_lymph_node',\n",
            "       'finding_no_finding', 'image_path', 'case_category', 'upsampled'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(image_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-U_axQNf52i",
        "outputId": "4ab2b568-70c9-4d48-f990-c70671eeb612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n",
            "Extracted to: /content/birads_preprocessed_dataset\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your zip file\n",
        "zip_path = \"/content/drive/MyDrive/multimodal_mammography/dataset/zipped_folder/birads_preprocessed_dataset.zip\"\n",
        "\n",
        "# Destination folder to extract files\n",
        "extract_dir = \"/content/birads_preprocessed_dataset\"\n",
        "\n",
        "# Make sure the directory exists\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"Extraction complete.\")\n",
        "print(\"Extracted to:\", extract_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sxFyOlLG5Nw",
        "outputId": "b3b6328a-d747-4b9f-d468-4ccc2250c647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root: /content/birads_preprocessed_dataset\n",
            "Subdirs: ['training', 'test']\n",
            "Files: ['image_df_upsampled_preprocessed.csv']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# List a few extracted files/folders\n",
        "for root, dirs, files in os.walk(extract_dir):\n",
        "    print(\"Root:\", root)\n",
        "    print(\"Subdirs:\", dirs[:5])   # show first 5 dirs\n",
        "    print(\"Files:\", files[:5])   # show first 5 files\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7KjRvUXX_oJ"
      },
      "source": [
        "Step-0c: Validating existing dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QsZ3A4PKxCu",
        "outputId": "9a5015c7-d15a-4825-abe3-55cc6d437676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All studies have at least 4 images.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "base_dir = \"/content/birads_preprocessed_dataset\"\n",
        "\n",
        "def find_small_studies(base_dir, min_images=4):\n",
        "    small_studies = defaultdict(list)\n",
        "\n",
        "    for split in [\"training\", \"test\"]:\n",
        "        for case in [\"normal\", \"abnormal\"]:\n",
        "            case_path = os.path.join(base_dir, split, case)\n",
        "            if not os.path.exists(case_path):\n",
        "                continue\n",
        "\n",
        "            for study in os.listdir(case_path):\n",
        "                study_path = os.path.join(case_path, study)\n",
        "                if not os.path.isdir(study_path):\n",
        "                    continue\n",
        "\n",
        "                imgs = [f for f in os.listdir(study_path) if f.endswith(\".png\")]\n",
        "                if len(imgs) < min_images:\n",
        "                    small_studies[(split, case, study)] = imgs\n",
        "\n",
        "    return small_studies\n",
        "\n",
        "small_studies = find_small_studies(base_dir)\n",
        "\n",
        "if small_studies:\n",
        "    print(\"‚ö†Ô∏è Studies with fewer than 4 images:\")\n",
        "    for (split, case, study), imgs in small_studies.items():\n",
        "        print(f\"- {split}/{case}/{study} -> {len(imgs)} images: {imgs}\")\n",
        "else:\n",
        "    print(\"‚úÖ All studies have at least 4 images.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHOxUndswzXO",
        "outputId": "3552d9b0-25fa-405b-bac7-c8a97c710017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image count per study distribution:\n",
            "4 images: 7999 studies\n",
            "\n",
            "Total studies counted: 7999\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "base_dir = \"/content/birads_preprocessed_dataset\"\n",
        "splits = [\"training\", \"test\"]\n",
        "classes = [\"normal\", \"abnormal\"]\n",
        "\n",
        "# Dictionary to store study -> image count\n",
        "study_image_counts = {}\n",
        "\n",
        "for split in splits:\n",
        "    split_path = os.path.join(base_dir, split)\n",
        "    for cls in classes:\n",
        "        cls_path = os.path.join(split_path, cls)\n",
        "        if not os.path.exists(cls_path):\n",
        "            continue\n",
        "        for study in os.listdir(cls_path):\n",
        "            study_path = os.path.join(cls_path, study)\n",
        "            if os.path.isdir(study_path):\n",
        "                images = [f for f in os.listdir(study_path) if f.endswith(\".png\")]\n",
        "                study_image_counts[study] = len(images)\n",
        "\n",
        "# Summarize the distribution of images per study\n",
        "count_distribution = Counter(study_image_counts.values())\n",
        "print(\"Image count per study distribution:\")\n",
        "for n_images, n_studies in sorted(count_distribution.items()):\n",
        "    print(f\"{n_images} images: {n_studies} studies\")\n",
        "\n",
        "# Optional: total studies\n",
        "print(f\"\\nTotal studies counted: {len(study_image_counts)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkyZcs3eweu1",
        "outputId": "98188e91-3cb0-4833-bac2-78063a8ed295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training/normal studies: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5065/5065 [02:01<00:00, 41.81it/s]\n",
            "training/abnormal studies: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1934/1934 [00:45<00:00, 42.11it/s]\n",
            "test/normal studies: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 916/916 [00:21<00:00, 43.33it/s]\n",
            "test/abnormal studies: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:02<00:00, 40.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fixed CSV saved at: /content/birads_preprocessed_dataset/image_df_preprocessed_fixed.csv\n",
            "Total studies included: 7999\n",
            "Total images included: 31996\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm  # import tqdm\n",
        "\n",
        "# Paths\n",
        "base_dir = \"/content/birads_preprocessed_dataset\"\n",
        "original_csv = os.path.join(base_dir, \"image_df_upsampled_preprocessed.csv\")\n",
        "fixed_csv = os.path.join(base_dir, \"image_df_preprocessed_fixed.csv\")\n",
        "\n",
        "# Load original CSV\n",
        "df_orig = pd.read_csv(original_csv)\n",
        "\n",
        "# Ensure string types for safe matching\n",
        "df_orig[\"study_id\"] = df_orig[\"study_id\"].astype(str)\n",
        "df_orig[\"filename\"] = df_orig[\"filename\"].astype(str)\n",
        "\n",
        "# Prepare list for final rows\n",
        "rows = []\n",
        "\n",
        "splits = [\"training\", \"test\"]\n",
        "classes = [\"normal\", \"abnormal\"]\n",
        "\n",
        "for split in splits:\n",
        "    split_path = os.path.join(base_dir, split)\n",
        "    if not os.path.exists(split_path):\n",
        "        continue\n",
        "\n",
        "    for cls in classes:\n",
        "        cls_path = os.path.join(split_path, cls)\n",
        "        if not os.path.exists(cls_path):\n",
        "            continue\n",
        "\n",
        "        study_list = [s for s in os.listdir(cls_path) if os.path.isdir(os.path.join(cls_path, s))]\n",
        "        for study in tqdm(study_list, desc=f\"{split}/{cls} studies\"):\n",
        "            study_path = os.path.join(cls_path, study)\n",
        "\n",
        "            images = sorted([f for f in os.listdir(study_path) if f.endswith(\".png\")])\n",
        "            if len(images) != 4:\n",
        "                continue  # only keep studies with exactly 4 images\n",
        "\n",
        "            for img in images:\n",
        "                # Try to get metadata from original CSV\n",
        "                match = df_orig[(df_orig[\"study_id\"] == study) &\n",
        "                                (df_orig[\"filename\"] == img)]\n",
        "                if not match.empty:\n",
        "                    row = match.iloc[0].copy()\n",
        "                    row[\"image_path\"] = os.path.join(study_path, img)  # update path\n",
        "                else:\n",
        "                    # If missing in original CSV, create minimal row with placeholders\n",
        "                    row = {col: -1 for col in df_orig.columns}  # -1 as placeholder\n",
        "                    row[\"study_id\"] = study\n",
        "                    row[\"filename\"] = img\n",
        "                    row[\"image_path\"] = os.path.join(study_path, img)\n",
        "                    row[\"split\"] = split\n",
        "                    row[\"case_category\"] = cls\n",
        "\n",
        "                rows.append(row)\n",
        "\n",
        "# Build DataFrame\n",
        "df_fixed = pd.DataFrame(rows)\n",
        "\n",
        "# Save CSV\n",
        "df_fixed.to_csv(fixed_csv, index=False)\n",
        "\n",
        "# Summary\n",
        "print(f\"‚úÖ Fixed CSV saved at: {fixed_csv}\")\n",
        "print(f\"Total studies included: {df_fixed['study_id'].nunique()}\")\n",
        "print(f\"Total images included: {len(df_fixed)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaHhbmSc1Ady",
        "outputId": "c7d8b244-e295-4376-f96a-cab2c5163320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['image_id', 'study_id', 'filename', 'birads', 'birads_dir', 'density',\n",
            "       'laterality', 'view_position', 'split', 'finding_categories',\n",
            "       'finding_birads_clean', 'xmin', 'ymin', 'xmax', 'ymax', 'has_bbox',\n",
            "       'age', 'birads_binary', 'birads_cleaned', 'birads_study_level',\n",
            "       'finding_mass', 'finding_suspicious_calcification',\n",
            "       'finding_focal_asymmetry', 'finding_asymmetry',\n",
            "       'finding_global_asymmetry', 'finding_architectural_distortion',\n",
            "       'finding_skin_thickening', 'finding_skin_retraction',\n",
            "       'finding_nipple_retraction', 'finding_suspicious_lymph_node',\n",
            "       'finding_no_finding', 'image_path', 'case_category', 'upsampled',\n",
            "       'preprocessed_path'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df_fixed.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF5zOxE0Fahz",
        "outputId": "ae186575-79dd-42e3-8281-cecf8eb844c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset structure matches CSV metadata and is valid.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Paths\n",
        "base_dir = \"/content/birads_preprocessed_dataset\"\n",
        "csv_path = os.path.join(base_dir, \"image_df_preprocessed_fixed.csv\")\n",
        "\n",
        "# Load CSV metadata\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Build sets for quick lookup\n",
        "expected_study_ids = set(df[\"study_id\"].astype(str).unique())\n",
        "expected_image_ids = set(df[\"image_id\"].astype(str).unique())\n",
        "\n",
        "issues = []\n",
        "\n",
        "# Iterate over splits and classes\n",
        "for split in [\"training\", \"test\"]:\n",
        "    for cls in [\"normal\", \"abnormal\"]:\n",
        "        cls_path = os.path.join(base_dir, split, cls)\n",
        "        if not os.path.exists(cls_path):\n",
        "            issues.append(f\"Missing folder: {cls_path}\")\n",
        "            continue\n",
        "\n",
        "        # Iterate over studies\n",
        "        for study in os.listdir(cls_path):\n",
        "            study_path = os.path.join(cls_path, study)\n",
        "            if not os.path.isdir(study_path):\n",
        "                continue\n",
        "\n",
        "            # Validate study ID\n",
        "            if study not in expected_study_ids:\n",
        "                issues.append(f\"Study folder '{study}' not found in CSV\")\n",
        "\n",
        "            # Validate image files\n",
        "            for img in os.listdir(study_path):\n",
        "                if img.endswith(\".png\"):\n",
        "                    img_id = os.path.splitext(img)[0]  # remove extension\n",
        "                    if img_id not in expected_image_ids:\n",
        "                        issues.append(f\"Image '{img}' in '{study_path}' not found in CSV\")\n",
        "\n",
        "# Summary\n",
        "if not issues:\n",
        "    print(\"‚úÖ Dataset structure matches CSV metadata and is valid.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Issues found:\")\n",
        "    for issue in issues:\n",
        "        print(\"-\", issue)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emiQxS3a3OP8",
        "outputId": "646dd043-c144-4d2f-8c24-c73c5acf4343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_id: 19996 unique values\n",
            "image_id\n",
            "7dbf6830cc06730cfe74cd58937f89a8    24\n",
            "2973bcf878fad1e9edade25be62602ce    24\n",
            "6266ffa44d75d2edc9d3c725b20b6d49    24\n",
            "2bd9c72b886e97da1aff1361962c6acc    24\n",
            "3cd51ee99070c4d625d52b848d5e9bfc    22\n",
            "10e0f362333df810ac84a9db8fb3fd42    22\n",
            "85a6579cbdc403cfc4dde0a8149ed855    22\n",
            "a7acc2e02a4944c4fc72e32507b17fa7    22\n",
            "136a7d195b654c4bf862fdd076c77574    21\n",
            "360a2637d08a1b3f8fef4f3a3e14e717    21\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "study_id: 7999 unique values\n",
            "study_id\n",
            "2df4404b9c286ec49851d4261faec924            4\n",
            "06638221ad71bf397e1109b67e425597            4\n",
            "0b666e8ea8e2a0772fcd18b528553565            4\n",
            "bbe408b621d15ba6fc1de8ee82dbb920            4\n",
            "b2b49d880f06ca420bae27d840082b2b            4\n",
            "094f43a5547f064caa95e2f160609904            4\n",
            "736680ada4d51ca3d582a2453a3060ed            4\n",
            "44c63ecd23616c4fce7e817470401d5d_dup1857    4\n",
            "8a12da7b03eed18bcae0bf177a71b560            4\n",
            "1b0eacc4e131185f50c3d366cda14307            4\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "filename: 19996 unique values\n",
            "filename\n",
            "7dbf6830cc06730cfe74cd58937f89a8.png    24\n",
            "2973bcf878fad1e9edade25be62602ce.png    24\n",
            "6266ffa44d75d2edc9d3c725b20b6d49.png    24\n",
            "2bd9c72b886e97da1aff1361962c6acc.png    24\n",
            "3cd51ee99070c4d625d52b848d5e9bfc.png    22\n",
            "10e0f362333df810ac84a9db8fb3fd42.png    22\n",
            "85a6579cbdc403cfc4dde0a8149ed855.png    22\n",
            "a7acc2e02a4944c4fc72e32507b17fa7.png    22\n",
            "136a7d195b654c4bf862fdd076c77574.png    21\n",
            "360a2637d08a1b3f8fef4f3a3e14e717.png    21\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "birads: 5 unique values\n",
            "birads\n",
            "1    17098\n",
            "2     6620\n",
            "4     4922\n",
            "5     2226\n",
            "3     1130\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "birads_dir: 5 unique values\n",
            "birads_dir\n",
            "birads_1    17098\n",
            "birads_2     6620\n",
            "birads_4     4922\n",
            "birads_5     2226\n",
            "birads_3     1130\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "density: 4 unique values\n",
            "density\n",
            "C    24574\n",
            "B     3818\n",
            "D     3468\n",
            "A      136\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "laterality: 2 unique values\n",
            "laterality\n",
            "L    15998\n",
            "R    15998\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "view_position: 2 unique values\n",
            "view_position\n",
            "CC     15998\n",
            "MLO    15998\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "split: 2 unique values\n",
            "split\n",
            "training    27996\n",
            "test         4000\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_categories: 91 unique values\n",
            "finding_categories\n",
            "[\"['No Finding']\"]                                                           24116\n",
            "[\"['Mass']\"]                                                                  3128\n",
            "[\"['Suspicious Calcification']\"]                                               940\n",
            "[\"['Focal Asymmetry']\"]                                                        623\n",
            "[\"['Mass']\", \"['Suspicious Calcification']\"]                                   546\n",
            "[\"['Suspicious Calcification', 'Mass']\"]                                       366\n",
            "[\"['Architectural Distortion']\"]                                               366\n",
            "[\"['Suspicious Calcification', 'Focal Asymmetry']\"]                            132\n",
            "[\"['Asymmetry']\"]                                                              121\n",
            "[\"['Mass']\", \"['Suspicious Lymph Node']\", \"['Suspicious Calcification']\"]       99\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_birads_clean: 7 unique values\n",
            "finding_birads_clean\n",
            "[]        24146\n",
            "[4]        4537\n",
            "[5]        1296\n",
            "[3]        1015\n",
            "[5, 4]      809\n",
            "[4, 3]      191\n",
            "[5, 3]        2\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "xmin: 1760 unique values\n",
            "xmin\n",
            "1421.530029    24\n",
            "1438.170044    24\n",
            "2465.381875    22\n",
            "2436.817041    22\n",
            "143.108002     21\n",
            "346.046997     21\n",
            "2315.649902    19\n",
            "2078.209961    19\n",
            "0.685536       18\n",
            "24.599501      18\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "ymin: 1759 unique values\n",
            "ymin\n",
            "1615.949951    24\n",
            "577.869995     24\n",
            "485.898724     22\n",
            "1833.121439    22\n",
            "1000.580017    21\n",
            "1135.739990    21\n",
            "1051.569946    19\n",
            "1161.699951    19\n",
            "1200.609985    19\n",
            "1271.020020    18\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "xmax: 1760 unique values\n",
            "xmax\n",
            "2790.610107    29\n",
            "1953.670044    24\n",
            "2008.739990    24\n",
            "2672.780256    22\n",
            "2655.419922    22\n",
            "532.539002     21\n",
            "708.348999     21\n",
            "2671.090088    19\n",
            "554.994019     18\n",
            "662.369019     18\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "ymax: 1755 unique values\n",
            "ymax\n",
            "1998.660034    24\n",
            "1214.150024    24\n",
            "2142.227302    22\n",
            "2122.822289    22\n",
            "1581.560059    21\n",
            "1328.229980    21\n",
            "1401.140015    21\n",
            "1644.310059    20\n",
            "1761.939941    19\n",
            "1857.670044    19\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "has_bbox: 2 unique values\n",
            "has_bbox\n",
            "0    24116\n",
            "1     7880\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "age: 66 unique values\n",
            "age\n",
            "45    5678\n",
            "47    1244\n",
            "42    1244\n",
            "43    1148\n",
            "49    1100\n",
            "44    1068\n",
            "56    1042\n",
            "41    1016\n",
            "46     980\n",
            "51     980\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "birads_binary: 2 unique values\n",
            "birads_binary\n",
            "normal      23718\n",
            "abnormal     8278\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "birads_cleaned: 5 unique values\n",
            "birads_cleaned\n",
            "1    17098\n",
            "2     6620\n",
            "4     4922\n",
            "5     2226\n",
            "3     1130\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "birads_study_level: 5 unique values\n",
            "birads_study_level\n",
            "1    10060\n",
            "4     9472\n",
            "2     6268\n",
            "5     4452\n",
            "3     1744\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_mass: 2 unique values\n",
            "finding_mass\n",
            "0    26772\n",
            "1     5224\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_suspicious_calcification: 2 unique values\n",
            "finding_suspicious_calcification\n",
            "0    29016\n",
            "1     2980\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_focal_asymmetry: 2 unique values\n",
            "finding_focal_asymmetry\n",
            "0    30892\n",
            "1     1104\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_asymmetry: 2 unique values\n",
            "finding_asymmetry\n",
            "0    31801\n",
            "1      195\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_global_asymmetry: 2 unique values\n",
            "finding_global_asymmetry\n",
            "0    31930\n",
            "1       66\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_architectural_distortion: 2 unique values\n",
            "finding_architectural_distortion\n",
            "0    31248\n",
            "1      748\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_skin_thickening: 2 unique values\n",
            "finding_skin_thickening\n",
            "0    31672\n",
            "1      324\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_skin_retraction: 2 unique values\n",
            "finding_skin_retraction\n",
            "0    31851\n",
            "1      145\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_nipple_retraction: 2 unique values\n",
            "finding_nipple_retraction\n",
            "0    31739\n",
            "1      257\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_suspicious_lymph_node: 2 unique values\n",
            "finding_suspicious_lymph_node\n",
            "0    31580\n",
            "1      416\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "finding_no_finding: 2 unique values\n",
            "finding_no_finding\n",
            "1    24116\n",
            "0     7880\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "image_path: 31996 unique values\n",
            "image_path\n",
            "/content/birads_preprocessed_dataset/test/abnormal/2df4404b9c286ec49851d4261faec924/dbf56903314294c63b9b255dc544fc48.png      1\n",
            "/content/birads_preprocessed_dataset/training/normal/06638221ad71bf397e1109b67e425597/181e63cb4ffaad44b81400c493a3a94f.png    1\n",
            "/content/birads_preprocessed_dataset/training/normal/06638221ad71bf397e1109b67e425597/a07c4d13639e48fe3f9b80d0bea0a7a3.png    1\n",
            "/content/birads_preprocessed_dataset/training/normal/06638221ad71bf397e1109b67e425597/acfdaa73de3066a071ca4b13b1e0f15d.png    1\n",
            "/content/birads_preprocessed_dataset/training/normal/06638221ad71bf397e1109b67e425597/e42cba584142f92dc42ef3fb95b5878d.png    1\n",
            "/content/birads_preprocessed_dataset/training/normal/0b666e8ea8e2a0772fcd18b528553565/15106683bbfc8f59d49ee64e3e44a484.png    1\n",
            "/content/birads_preprocessed_dataset/training/normal/0b666e8ea8e2a0772fcd18b528553565/6b7baf3a8511769bd615e462df534ffe.png    1\n",
            "/content/birads_preprocessed_dataset/training/normal/0b666e8ea8e2a0772fcd18b528553565/8de03802047f0890c395c5098bf0b9f0.png    1\n",
            "/content/birads_preprocessed_dataset/training/normal/0b666e8ea8e2a0772fcd18b528553565/fdc1c5087c5f2728506a9c9dc8e5e885.png    1\n",
            "/content/birads_preprocessed_dataset/training/normal/bbe408b621d15ba6fc1de8ee82dbb920/04203a7c5d5382b6227ff85b38882eda.png    1\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "case_category: 3 unique values\n",
            "case_category\n",
            "0    18072\n",
            "1     9472\n",
            "2     4452\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "upsampled: 2 unique values\n",
            "upsampled\n",
            "False    19996\n",
            "True     12000\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n",
            "preprocessed_path: 31996 unique values\n",
            "preprocessed_path\n",
            "/content/birads_preprocessed_dataset/training/normal/175a70fed8dcf5dd0625d4ae7115eeb5/823cb056e0f258fe2677aa6e299142c7.png             1\n",
            "/content/birads_preprocessed_dataset/test/normal/16f6c892b53e8f60d89da454c5a3b042/536404d9db2828d0a4bd2be1369a52bc.png                 1\n",
            "/content/birads_preprocessed_dataset/training/normal/be4341c9244a5968a8c485279707960f/3353a1bd7f901b40adeda23bc44f5eb8.png             1\n",
            "/content/birads_preprocessed_dataset/training/normal/28b0da83ab46cc8371b501ab005c88b7_dup1804/e45c5993ab3a5c28b0f5ed32a0c204b9.png     1\n",
            "/content/birads_preprocessed_dataset/test/normal/68107a7fd1e370b88e161f37cff1c2d7/352f8e70555245091657f3810f50e10d.png                 1\n",
            "/content/birads_preprocessed_dataset/training/normal/4d100012e6e8bd1ce4ecee057eb5c118/dd65f3a938b26a398b7da90e16610c4c.png             1\n",
            "/content/birads_preprocessed_dataset/training/normal/b637bc3a2d5aa8842b92b7b4d7cab620_dup11383/8c90a9536079688965102363c77df077.png    1\n",
            "/content/birads_preprocessed_dataset/training/normal/188998c43ceb69d4cf4da4eba2c53b74_dup11576/b82a26c37874bfb1e7809a4405691d50.png    1\n",
            "/content/birads_preprocessed_dataset/training/normal/8096a11267a09d240f371440e4e3104e/a2d0d0d80b85b0368867cece39fb7341.png             1\n",
            "/content/birads_preprocessed_dataset/training/normal/4e68395c78947a8dd8f745e90096d351/f28b3ea2ae255dae644357efc5dce523.png             1\n",
            "Name: count, dtype: int64\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "base_dir = \"/content/birads_preprocessed_dataset\"\n",
        "csv_path = os.path.join(base_dir, \"image_df_preprocessed_fixed.csv\")\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Iterate over all columns and print unique values and counts\n",
        "for col in df.columns:\n",
        "    unique_vals = df[col].nunique()\n",
        "    print(f\"{col}: {unique_vals} unique values\")\n",
        "    # Optionally, show top 10 most frequent values\n",
        "    print(df[col].value_counts().head(10))\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzsXcb9qcE78"
      },
      "source": [
        "Step-1: Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwz63LW_YZwQ",
        "outputId": "40c73029-fc92-4ea5-a506-d2cf004625f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final study-level CSV saved to: /content/birads_preprocessed_dataset/study_level_metadata.csv\n",
            "Shape: (7999, 7)\n",
            "Columns: ['study_id', 'age', 'density_A', 'density_B', 'density_C', 'density_D', 'birads_binary']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Paths\n",
        "base_dir = \"/content/birads_preprocessed_dataset\"\n",
        "csv_path = os.path.join(base_dir, \"image_df_preprocessed_fixed.csv\")\n",
        "output_csv_path = os.path.join(base_dir, \"study_level_metadata.csv\")\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Keep only study-level rows (drop image duplicates)\n",
        "df_study = df.drop_duplicates(subset=[\"study_id\"]).reset_index(drop=True)\n",
        "\n",
        "# Target variable\n",
        "df_study[\"birads_binary_num\"] = df_study[\"birads_binary\"].map({\"normal\": 0, \"abnormal\": 1})\n",
        "\n",
        "# Features: age + density only\n",
        "num_features = [\"age\"]\n",
        "cat_features = [\"density\"]\n",
        "\n",
        "X = df_study[num_features + cat_features]\n",
        "\n",
        "# Preprocessing: scale numeric + one-hot encode categorical (keep all categories)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), num_features),\n",
        "        (\"cat\", OneHotEncoder(drop=None, sparse_output=False), cat_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply preprocessing\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Get one-hot density column names\n",
        "density_cols = preprocessor.named_transformers_[\"cat\"].get_feature_names_out(cat_features)\n",
        "\n",
        "# Build final DataFrame\n",
        "import numpy as np\n",
        "df_final = pd.DataFrame(\n",
        "    np.hstack([X_processed, df_study[\"birads_binary_num\"].values.reshape(-1, 1)]),\n",
        "    columns=list(num_features) + list(density_cols) + [\"birads_binary\"]\n",
        ")\n",
        "\n",
        "# Add study_id for reference\n",
        "df_final[\"study_id\"] = df_study[\"study_id\"].values\n",
        "\n",
        "# Reorder columns: study_id first\n",
        "df_final = df_final[[\"study_id\"] + list(num_features) + list(density_cols) + [\"birads_binary\"]]\n",
        "\n",
        "# Save to CSV\n",
        "df_final.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(\"Final study-level CSV saved to:\", output_csv_path)\n",
        "print(\"Shape:\", df_final.shape)\n",
        "print(\"Columns:\", df_final.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oynfM-AXjt9p"
      },
      "source": [
        "Step-2: Model Result based on only metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXfbVkbNctbx",
        "outputId": "e7adcc63-87df-49c8-8237-7ca858fbce68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw features shape: (7999, 5)\n",
            "Train: (5599, 5), Val: (1400, 5), Test: (1000, 5)\n",
            "\n",
            "=== Logistic Regression ===\n",
            "Val AUROC: 0.5807\n",
            "Val AUPRC: 0.3265\n",
            "Test AUROC: 0.5698\n",
            "Test AUPRC: 0.3177\n",
            "Test Accuracy: 0.5800\n",
            "Test F1: 0.3913\n",
            "Test Brier Score: 0.2455\n",
            "\n",
            "=== XGBoost ===\n",
            "Val AUROC: 0.6988\n",
            "Val AUPRC: 0.4504\n",
            "Test AUROC: 0.6571\n",
            "Test AUPRC: 0.4160\n",
            "Test Accuracy: 0.6860\n",
            "Test F1: 0.4332\n",
            "Test Brier Score: 0.2244\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score,\n",
        "    accuracy_score, f1_score, brier_score_loss\n",
        ")\n",
        "import xgboost as xgb\n",
        "\n",
        "# Paths\n",
        "base_dir = \"/content/birads_preprocessed_dataset\"\n",
        "csv_path = os.path.join(base_dir, \"study_level_metadata.csv\")\n",
        "\n",
        "# Load study-level dataset\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Features and target\n",
        "feature_cols = [col for col in df.columns if col not in [\"study_id\", \"birads_binary\"]]\n",
        "X = df[feature_cols].values\n",
        "y = df[\"birads_binary\"].values\n",
        "study_ids = df[\"study_id\"].values\n",
        "\n",
        "print(\"Raw features shape:\", X.shape)\n",
        "\n",
        "# Study-wise split\n",
        "train_ids, test_ids, y_train_ids, y_test_ids = train_test_split(\n",
        "    study_ids, y, test_size=0.125, random_state=42, stratify=y\n",
        ")\n",
        "train_ids, val_ids, y_train_ids, y_val_ids = train_test_split(\n",
        "    train_ids, y_train_ids, test_size=0.2, random_state=42, stratify=y_train_ids\n",
        ")\n",
        "\n",
        "# Masks for indexing\n",
        "train_mask = np.isin(study_ids, train_ids)\n",
        "val_mask = np.isin(study_ids, val_ids)\n",
        "test_mask = np.isin(study_ids, test_ids)\n",
        "\n",
        "X_train, y_train = X[train_mask], y[train_mask]\n",
        "X_val, y_val = X[val_mask], y[val_mask]\n",
        "X_test, y_test = X[test_mask], y[test_mask]\n",
        "\n",
        "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Logistic Regression\n",
        "# -------------------------------\n",
        "logreg = LogisticRegression(max_iter=500, class_weight=\"balanced\", solver=\"liblinear\")\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred = logreg.predict_proba(X_val)[:, 1]\n",
        "y_test_pred = logreg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n=== Logistic Regression ===\")\n",
        "print(f\"Val AUROC: {roc_auc_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"Val AUPRC: {average_precision_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"Test AUROC: {roc_auc_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test AUPRC: {average_precision_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, (y_test_pred > 0.5)):.4f}\")\n",
        "print(f\"Test F1: {f1_score(y_test, (y_test_pred > 0.5)):.4f}\")\n",
        "print(f\"Test Brier Score: {brier_score_loss(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# XGBoost\n",
        "# -------------------------------\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"auc\",\n",
        "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
        "    use_label_encoder=False,\n",
        "    random_state=42,\n",
        "    n_estimators=200,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.05\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
        "\n",
        "y_val_pred = xgb_model.predict_proba(X_val)[:, 1]\n",
        "y_test_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n=== XGBoost ===\")\n",
        "print(f\"Val AUROC: {roc_auc_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"Val AUPRC: {average_precision_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"Test AUROC: {roc_auc_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test AUPRC: {average_precision_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, (y_test_pred > 0.5)):.4f}\")\n",
        "print(f\"Test F1: {f1_score(y_test, (y_test_pred > 0.5)):.4f}\")\n",
        "print(f\"Test Brier Score: {brier_score_loss(y_test, y_test_pred):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZDJfVHNj2d_"
      },
      "source": [
        "Step-3: Setting up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSQwO9gGGK5t",
        "outputId": "a32c5517-4c5c-47b1-ed0d-04579837b85e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah_-9s1ZX6Sd"
      },
      "source": [
        "Step-4: Creating fusion level dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IomEFbRbIaZ6",
        "outputId": "90be1e69-4b50-4432-8c99-b5ad16c6eeaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final study-level CSV saved to: /content/birads_preprocessed_dataset/study_level_metadata.csv\n",
            "Shape: (7999, 19)\n",
            "Columns: ['study_id', 'age', 'birads_binary', 'split', 'case_category', 'density_A', 'density_B', 'density_C', 'density_D', 'image_path', 'preprocessed_path', 'L_MLO_path', 'L_CC_path', 'R_MLO_path', 'R_CC_path', 'L_MLO_idx', 'L_CC_idx', 'R_MLO_idx', 'R_CC_idx']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ----------------------------\n",
        "# Paths\n",
        "# ----------------------------\n",
        "base_dir = \"/content/birads_preprocessed_dataset\"\n",
        "csv_path = os.path.join(base_dir, \"image_df_preprocessed_fixed.csv\")\n",
        "\n",
        "# ----------------------------\n",
        "# Load CSV and map labels\n",
        "# ----------------------------\n",
        "df = pd.read_csv(csv_path)\n",
        "df[\"birads_binary\"] = df[\"birads_binary\"].map({\"normal\": 0, \"abnormal\": 1})\n",
        "\n",
        "# ----------------------------\n",
        "# Keep only complete studies and map images\n",
        "# ----------------------------\n",
        "study_groups = []\n",
        "for study_id, group in df.groupby(\"study_id\"):\n",
        "    if len(group) == 4:  # L-CC, L-MLO, R-CC, R-MLO\n",
        "        row = group.iloc[0].copy()  # representative row\n",
        "        row[\"study_id\"] = study_id\n",
        "\n",
        "        # Assign split and case_category from first row\n",
        "        row[\"split\"] = group[\"split\"].iloc[0]\n",
        "        row[\"case_category\"] = group[\"case_category\"].iloc[0]\n",
        "\n",
        "        # Map image paths and indices\n",
        "        for idx, img_row in enumerate(group.itertuples()):\n",
        "            pos_col_path = f\"{img_row.laterality}_{img_row.view_position}_path\"\n",
        "            pos_col_idx  = f\"{img_row.laterality}_{img_row.view_position}_idx\"\n",
        "            row[pos_col_path] = img_row.image_path\n",
        "            row[pos_col_idx]  = idx  # 0-3 index within study\n",
        "\n",
        "        study_groups.append(row)\n",
        "\n",
        "fusion_df = pd.DataFrame(study_groups)\n",
        "\n",
        "# ----------------------------\n",
        "# One-hot encode density\n",
        "# ----------------------------\n",
        "ohe = OneHotEncoder(drop=None, sparse_output=False)\n",
        "density_encoded = ohe.fit_transform(fusion_df[[\"density\"]])\n",
        "density_cols = ohe.get_feature_names_out([\"density\"])\n",
        "density_df = pd.DataFrame(density_encoded, columns=density_cols)\n",
        "\n",
        "# ----------------------------\n",
        "# Build final study-level DataFrame\n",
        "# ----------------------------\n",
        "final_cols = [\"study_id\", \"age\", \"birads_binary\", \"split\", \"case_category\"]\n",
        "# Collect all image path and index columns\n",
        "image_path_cols = [col for col in fusion_df.columns if col.endswith(\"_path\")]\n",
        "image_idx_cols  = [col for col in fusion_df.columns if col.endswith(\"_idx\")]\n",
        "\n",
        "final_df = pd.concat([\n",
        "    fusion_df[final_cols].reset_index(drop=True),\n",
        "    density_df.reset_index(drop=True),\n",
        "    fusion_df[image_path_cols + image_idx_cols].reset_index(drop=True)\n",
        "], axis=1)\n",
        "\n",
        "# ----------------------------\n",
        "# Save CSV\n",
        "# ----------------------------\n",
        "final_csv_path = os.path.join(base_dir, \"study_level_metadata.csv\")\n",
        "final_df.to_csv(final_csv_path, index=False)\n",
        "\n",
        "print(\"Final study-level CSV saved to:\", final_csv_path)\n",
        "print(\"Shape:\", final_df.shape)\n",
        "print(\"Columns:\", final_df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeeSxmVihZM7",
        "outputId": "a8eaa3a4-e20e-4cb3-f898-29cff7f446da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    study_id  age  birads_binary     split  \\\n",
            "0           0025a5dc99fd5c742026f0b2b030d3e9   44              0      test   \n",
            "1           0028fb2c7f0b3a5cb9a80cb0e1cdbb91   51              0  training   \n",
            "2           0034765af074f93ed33d5e8399355caf   37              0  training   \n",
            "3           003700f3c960e0b9bca2b8437c3dbf05   44              0  training   \n",
            "4  003700f3c960e0b9bca2b8437c3dbf05_dup11243   44              0  training   \n",
            "\n",
            "   case_category  density_A  density_B  density_C  density_D  \\\n",
            "0              0        0.0        0.0        1.0        0.0   \n",
            "1              0        0.0        0.0        1.0        0.0   \n",
            "2              0        0.0        0.0        1.0        0.0   \n",
            "3              1        0.0        0.0        1.0        0.0   \n",
            "4              1        0.0        0.0        1.0        0.0   \n",
            "\n",
            "                                          image_path  \\\n",
            "0  /content/birads_preprocessed_dataset/test/norm...   \n",
            "1  /content/birads_preprocessed_dataset/training/...   \n",
            "2  /content/birads_preprocessed_dataset/training/...   \n",
            "3  /content/birads_preprocessed_dataset/training/...   \n",
            "4  /content/birads_preprocessed_dataset/training/...   \n",
            "\n",
            "                                   preprocessed_path  \\\n",
            "0  /content/birads_preprocessed_dataset/training/...   \n",
            "1  /content/birads_preprocessed_dataset/training/...   \n",
            "2  /content/birads_preprocessed_dataset/training/...   \n",
            "3  /content/birads_preprocessed_dataset/training/...   \n",
            "4  /content/birads_preprocessed_dataset/training/...   \n",
            "\n",
            "                                          L_MLO_path  \\\n",
            "0  /content/birads_preprocessed_dataset/test/norm...   \n",
            "1  /content/birads_preprocessed_dataset/training/...   \n",
            "2  /content/birads_preprocessed_dataset/training/...   \n",
            "3  /content/birads_preprocessed_dataset/training/...   \n",
            "4  /content/birads_preprocessed_dataset/training/...   \n",
            "\n",
            "                                           L_CC_path  \\\n",
            "0  /content/birads_preprocessed_dataset/test/norm...   \n",
            "1  /content/birads_preprocessed_dataset/training/...   \n",
            "2  /content/birads_preprocessed_dataset/training/...   \n",
            "3  /content/birads_preprocessed_dataset/training/...   \n",
            "4  /content/birads_preprocessed_dataset/training/...   \n",
            "\n",
            "                                          R_MLO_path  \\\n",
            "0  /content/birads_preprocessed_dataset/test/norm...   \n",
            "1  /content/birads_preprocessed_dataset/training/...   \n",
            "2  /content/birads_preprocessed_dataset/training/...   \n",
            "3  /content/birads_preprocessed_dataset/training/...   \n",
            "4  /content/birads_preprocessed_dataset/training/...   \n",
            "\n",
            "                                           R_CC_path  L_MLO_idx  L_CC_idx  \\\n",
            "0  /content/birads_preprocessed_dataset/test/norm...          0         1   \n",
            "1  /content/birads_preprocessed_dataset/training/...          2         1   \n",
            "2  /content/birads_preprocessed_dataset/training/...          2         1   \n",
            "3  /content/birads_preprocessed_dataset/training/...          1         2   \n",
            "4  /content/birads_preprocessed_dataset/training/...          1         2   \n",
            "\n",
            "   R_MLO_idx  R_CC_idx  \n",
            "0          2         3  \n",
            "1          0         3  \n",
            "2          3         0  \n",
            "3          3         0  \n",
            "4          3         0  \n"
          ]
        }
      ],
      "source": [
        "print(final_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cGx7OJIwQsI",
        "outputId": "9cd65c06-80e3-4903-8aa4-b84e11f2e14c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total studies in study_level_metadata.csv: 7999\n",
            "Unique studies in image_df: 7999\n",
            "Incomplete studies in image_df (should be 0): 0\n",
            "Missing image files in study_level_metadata.csv: 0\n",
            "Studies only in study_level_metadata.csv: 0\n",
            "Studies only in image_df: 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ----------------------------\n",
        "# Load original study-level CSV (fusion CSV)\n",
        "# ----------------------------\n",
        "study_csv_path = \"/content/birads_preprocessed_dataset/study_level_metadata.csv\"\n",
        "study_df = pd.read_csv(study_csv_path)\n",
        "\n",
        "# ----------------------------\n",
        "# Load image_df for comparison\n",
        "# ----------------------------\n",
        "image_df_path = \"/content/drive/MyDrive/multimodal_mammography/dataset/csv/image_df_upsampled_studywise.csv\"\n",
        "image_df = pd.read_csv(image_df_path)\n",
        "\n",
        "# ----------------------------\n",
        "# 1Ô∏è‚É£ Check study counts\n",
        "# ----------------------------\n",
        "print(\"Total studies in study_level_metadata.csv:\", len(study_df))\n",
        "print(\"Unique studies in image_df:\", image_df['study_id'].nunique())\n",
        "\n",
        "# ----------------------------\n",
        "# 2Ô∏è‚É£ Validate that each study has 4 images\n",
        "# ----------------------------\n",
        "# Count images per study in image_df\n",
        "study_counts = image_df.groupby(\"study_id\")[\"image_id\"].count()\n",
        "incomplete_studies = study_counts[study_counts != 4]\n",
        "print(\"Incomplete studies in image_df (should be 0):\", len(incomplete_studies))\n",
        "\n",
        "# ----------------------------\n",
        "# 3Ô∏è‚É£ Validate that paths exist in filesystem\n",
        "# ----------------------------\n",
        "missing_paths = []\n",
        "for col in [c for c in study_df.columns if c.endswith(\"_path\")]:\n",
        "    for p in study_df[col]:\n",
        "        if not os.path.exists(p):\n",
        "            missing_paths.append(p)\n",
        "print(\"Missing image files in study_level_metadata.csv:\", len(missing_paths))\n",
        "\n",
        "# ----------------------------\n",
        "# 4Ô∏è‚É£ Optional: Check all studies match\n",
        "# ----------------------------\n",
        "merged = pd.merge(study_df[['study_id']], image_df[['study_id']].drop_duplicates(), on='study_id', how='outer', indicator=True)\n",
        "print(\"Studies only in study_level_metadata.csv:\", merged[merged['_merge']=='left_only'].shape[0])\n",
        "print(\"Studies only in image_df:\", merged[merged['_merge']=='right_only'].shape[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqSyPKYokljx"
      },
      "source": [
        "Step-5: Multimodal Class and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aV5c6f8mpYn",
        "outputId": "71b1f29a-4676-490b-c5ba-5383a68ce957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train studies: 5599\n",
            "Val studies: 1400\n",
            "Test studies: 1000\n",
            "Images: torch.Size([4, 4, 3, 224, 224])\n",
            "Metadata: torch.Size([4, 6])\n",
            "Labels: tensor([0, 1, 0, 0])\n",
            "Case categories: tensor([0, 1, 0, 0])\n",
            "Study IDs: ['40fd03a5bb87d107c5807c0f89076b0d', 'e4c3b57bc18e8474140b62bc2eb6c0c7_dup1215', '857e8fcdea4691ce1c5eb7ea7c849b9d', 'b2deb4a18f3ebd2ea976864f1117b00c']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "import torchvision.transforms as T\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "\n",
        "# ----------------------------\n",
        "# Paths\n",
        "# ----------------------------\n",
        "BASE_DIR = \"/content/birads_preprocessed_dataset\"\n",
        "CSV_PATH = os.path.join(BASE_DIR, \"study_level_metadata.csv\")\n",
        "\n",
        "# ----------------------------\n",
        "# Load CSV\n",
        "# ----------------------------\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df[\"birads_binary\"] = df[\"birads_binary\"].astype(int)\n",
        "df[\"case_category\"] = df[\"case_category\"].astype(int)\n",
        "\n",
        "# ----------------------------\n",
        "# Image transforms\n",
        "# ----------------------------\n",
        "IMAGE_TRANSFORMS = {\n",
        "    \"train\": T.Compose([\n",
        "        T.Grayscale(num_output_channels=3),\n",
        "        T.Resize((224, 224)),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.RandomRotation(10),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.485, 0.456, 0.406],\n",
        "                    [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \"val\": T.Compose([\n",
        "        T.Grayscale(num_output_channels=3),\n",
        "        T.Resize((224, 224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.485, 0.456, 0.406],\n",
        "                    [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \"test\": T.Compose([\n",
        "        T.Grayscale(num_output_channels=3),\n",
        "        T.Resize((224, 224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.485, 0.456, 0.406],\n",
        "                    [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "# ----------------------------\n",
        "# Study-level dataset\n",
        "# ----------------------------\n",
        "class MammogramStudyDataset(Dataset):\n",
        "    def __init__(self, df, split=\"training\", transform=None, metadata_cols=None):\n",
        "        self.df_split = df[df[\"split\"] == split].copy()\n",
        "        self.transform = transform\n",
        "        self.metadata_cols = metadata_cols or [\"age\", \"density_A\", \"density_B\", \"density_C\", \"density_D\", \"case_category\"]\n",
        "\n",
        "        # Prepare study dictionary\n",
        "        self.study_groups = {}\n",
        "        for _, row in self.df_split.iterrows():\n",
        "            images = [row[\"L_CC_path\"], row[\"L_MLO_path\"], row[\"R_CC_path\"], row[\"R_MLO_path\"]]\n",
        "            if all(os.path.exists(p) for p in images):\n",
        "                self.study_groups[row[\"study_id\"]] = {\n",
        "                    \"images\": images,\n",
        "                    \"metadata\": row[self.metadata_cols].values.astype(np.float32),\n",
        "                    \"label\": row[\"birads_binary\"],\n",
        "                    \"case_category\": row[\"case_category\"]\n",
        "                }\n",
        "\n",
        "        self.study_ids = list(self.study_groups.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.study_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        study_id = self.study_ids[idx]\n",
        "        study = self.study_groups[study_id]\n",
        "\n",
        "        images = [Image.open(p).convert(\"RGB\") for p in study[\"images\"]]\n",
        "        if self.transform:\n",
        "            images = [self.transform(img) for img in images]\n",
        "        images = torch.stack(images)  # (4, C, H, W)\n",
        "\n",
        "        metadata = torch.tensor(study[\"metadata\"], dtype=torch.float32)\n",
        "        label = torch.tensor(study[\"label\"], dtype=torch.long)\n",
        "        return images, metadata, label, study[\"case_category\"], study_id\n",
        "\n",
        "# ----------------------------\n",
        "# Stratified batch sampler by case_category\n",
        "# ----------------------------\n",
        "class RepresentativeBatchSampler(Sampler):\n",
        "    def __init__(self, dataset, batch_size=4, seed=42):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        random.seed(seed)\n",
        "\n",
        "        # Group indices by case_category\n",
        "        self.cat_indices = defaultdict(list)\n",
        "        for idx, study_id in enumerate(dataset.study_ids):\n",
        "            cat = dataset.study_groups[study_id][\"case_category\"]\n",
        "            self.cat_indices[cat].append(idx)\n",
        "\n",
        "        for k in self.cat_indices:\n",
        "            random.shuffle(self.cat_indices[k])\n",
        "\n",
        "    def __iter__(self):\n",
        "        cat_lists = {k: list(v) for k, v in self.cat_indices.items()}\n",
        "        batches = []\n",
        "\n",
        "        while any(len(lst) > 0 for lst in cat_lists.values()):\n",
        "            batch = []\n",
        "            # pick one from each category if possible\n",
        "            for cat in sorted(cat_lists.keys()):\n",
        "                if cat_lists[cat]:\n",
        "                    batch.append(cat_lists[cat].pop())\n",
        "                if len(batch) == self.batch_size:\n",
        "                    break\n",
        "            # fill remaining slots if batch not full\n",
        "            remaining = [i for lst in cat_lists.values() for i in lst]\n",
        "            random.shuffle(remaining)\n",
        "            while len(batch) < self.batch_size and remaining:\n",
        "                batch.append(remaining.pop())\n",
        "            if batch:\n",
        "                batches.append(batch)\n",
        "\n",
        "        random.shuffle(batches)\n",
        "        return iter(batches)\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.dataset) + self.batch_size - 1) // self.batch_size\n",
        "\n",
        "# ----------------------------\n",
        "# Metadata columns\n",
        "# ----------------------------\n",
        "metadata_cols = [\"age\", \"density_A\", \"density_B\", \"density_C\", \"density_D\", \"case_category\"]\n",
        "\n",
        "# ----------------------------\n",
        "# Create datasets\n",
        "# ----------------------------\n",
        "train_dataset = MammogramStudyDataset(df, split=\"training\", transform=IMAGE_TRANSFORMS[\"train\"], metadata_cols=metadata_cols)\n",
        "val_dataset   = MammogramStudyDataset(df, split=\"training\", transform=IMAGE_TRANSFORMS[\"val\"], metadata_cols=metadata_cols)\n",
        "test_dataset  = MammogramStudyDataset(df, split=\"test\", transform=IMAGE_TRANSFORMS[\"test\"], metadata_cols=metadata_cols)\n",
        "\n",
        "# Manual train/val split\n",
        "train_ids, val_ids = train_test_split(train_dataset.study_ids, test_size=0.2, random_state=42)\n",
        "train_dataset.study_ids = train_ids\n",
        "val_dataset.study_ids = val_ids\n",
        "\n",
        "# ----------------------------\n",
        "# Dataloaders\n",
        "# ----------------------------\n",
        "batch_size = 4\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_sampler=RepresentativeBatchSampler(train_dataset, batch_size=batch_size),\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# ----------------------------\n",
        "# Summary\n",
        "# ----------------------------\n",
        "print(\"Train studies:\", len(train_dataset))\n",
        "print(\"Val studies:\", len(val_dataset))\n",
        "print(\"Test studies:\", len(test_dataset))\n",
        "\n",
        "# ----------------------------\n",
        "# Test first batch\n",
        "# ----------------------------\n",
        "for imgs, metadata, labels, case_cat, study_ids in train_loader:\n",
        "    print(\"Images:\", imgs.shape)\n",
        "    print(\"Metadata:\", metadata.shape)\n",
        "    print(\"Labels:\", labels)\n",
        "    print(\"Case categories:\", case_cat)\n",
        "    print(\"Study IDs:\", study_ids)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4f5ML8PpNUt"
      },
      "source": [
        "Step-6: Model Defintion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvggMtz09utI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class StudyLevelMultimodalNet(nn.Module):\n",
        "    def __init__(self, backbone=\"resnet50\", pretrained=True, num_metadata_features=6, num_classes=1):\n",
        "        super(StudyLevelMultimodalNet, self).__init__()\n",
        "\n",
        "        # ----------------------------\n",
        "        # Image backbone\n",
        "        # ----------------------------\n",
        "        if backbone == \"resnet50\":\n",
        "            self.cnn = models.resnet50(pretrained=pretrained)\n",
        "            in_features = self.cnn.fc.in_features\n",
        "            self.cnn.fc = nn.Identity()  # remove final classification layer\n",
        "        elif backbone == \"efficientnet_b0\":\n",
        "            self.cnn = models.efficientnet_b0(pretrained=pretrained)\n",
        "            in_features = self.cnn.classifier[1].in_features\n",
        "            self.cnn.classifier = nn.Identity()\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported backbone: {backbone}\")\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.num_metadata_features = num_metadata_features\n",
        "\n",
        "        # ----------------------------\n",
        "        # Study-level fusion + multimodal head\n",
        "        # ----------------------------\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features + num_metadata_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)  # binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, images, metadata):\n",
        "        \"\"\"\n",
        "        images: (batch_size, num_views, C, H, W)\n",
        "        metadata: (batch_size, num_metadata_features)\n",
        "        \"\"\"\n",
        "        batch_size, num_views, C, H, W = images.shape\n",
        "        x = images.view(batch_size * num_views, C, H, W)\n",
        "\n",
        "        # Extract features per view\n",
        "        feats = self.cnn(x)  # (batch_size*num_views, in_features)\n",
        "        feats = feats.view(batch_size, num_views, -1)\n",
        "\n",
        "        # Fuse across views (mean pooling)\n",
        "        fused_img_feats = feats.mean(dim=1)  # (batch_size, in_features)\n",
        "\n",
        "        # Concatenate metadata\n",
        "        fused = torch.cat([fused_img_feats, metadata], dim=1)  # (batch_size, in_features + num_metadata_features)\n",
        "\n",
        "        # Classification head\n",
        "        out = self.fc(fused).squeeze(1)  # (batch_size,)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKqO8miuJUWd",
        "outputId": "ab488aff-7e5a-4099-fd87-3716ee01df29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 164MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multimodal model ready on device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ----------------------------\n",
        "# Model setup\n",
        "# ----------------------------\n",
        "num_metadata_features = 6  # e.g., age + density one-hot\n",
        "model = StudyLevelMultimodalNet(\n",
        "    backbone=\"resnet50\",\n",
        "    pretrained=True,\n",
        "    num_metadata_features=num_metadata_features,\n",
        "    num_classes=1\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "# ----------------------------\n",
        "# Loss function\n",
        "# ----------------------------\n",
        "criterion = nn.BCEWithLogitsLoss()  # for binary classification\n",
        "\n",
        "# ----------------------------\n",
        "# Optimizer\n",
        "# ----------------------------\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# LR scheduler\n",
        "# ----------------------------\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode=\"max\",     # maximize monitored metric (val AUROC)\n",
        "    factor=0.5,     # reduce LR by 50%\n",
        "    patience=2      # wait 2 epochs before reducing\n",
        ")\n",
        "\n",
        "print(f\"Multimodal model ready on device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cVT3E4gJgtJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, f1_score, brier_score_loss\n",
        "\n",
        "# -----------------------------\n",
        "# Metrics helper\n",
        "# -----------------------------\n",
        "def compute_metrics(y_true, y_pred_probs):\n",
        "    y_pred = (y_pred_probs >= 0.5).astype(int)\n",
        "    return {\n",
        "        \"AUROC\": roc_auc_score(y_true, y_pred_probs),\n",
        "        \"AUPRC\": average_precision_score(y_true, y_pred_probs),\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"F1\": f1_score(y_true, y_pred),\n",
        "        \"Brier\": brier_score_loss(y_true, y_pred_probs)\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# Training one epoch\n",
        "# -----------------------------\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_labels, all_preds = [], []\n",
        "\n",
        "    loop = tqdm(loader, desc=\"Training\", leave=False)\n",
        "    for images, metadata, labels, _, _ in loop:  # unpack multimodal batch\n",
        "        images, metadata, labels = images.to(device), metadata.to(device), labels.float().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images, metadata)  # pass both modalities\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(torch.sigmoid(outputs).detach().cpu().numpy())\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    metrics = compute_metrics(np.array(all_labels), np.array(all_preds))\n",
        "    return total_loss / len(loader.dataset), metrics\n",
        "\n",
        "# -----------------------------\n",
        "# Validation\n",
        "# -----------------------------\n",
        "def validate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_labels, all_preds = []\n",
        "\n",
        "    loop = tqdm(loader, desc=\"Validation\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for images, metadata, labels, _, _ in loop:\n",
        "            images, metadata, labels = images.to(device), metadata.to(device), labels.float().to(device)\n",
        "            outputs = model(images, metadata)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    metrics = compute_metrics(np.array(all_labels), np.array(all_preds))\n",
        "    return total_loss / len(loader.dataset), metrics\n",
        "\n",
        "# -----------------------------\n",
        "# Full training loop\n",
        "# -----------------------------\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=10):\n",
        "    best_val_auroc = 0.0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"\\n=== Epoch {epoch}/{epochs} ===\")\n",
        "\n",
        "        train_loss, train_metrics = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_metrics = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "        print(f\"Train AUROC: {train_metrics['AUROC']:.4f} | Val AUROC: {val_metrics['AUROC']:.4f}\")\n",
        "        print(f\"Train Accuracy: {train_metrics['Accuracy']:.4f} | Val Accuracy: {val_metrics['Accuracy']:.4f}\")\n",
        "\n",
        "        # Step scheduler based on validation AUROC\n",
        "        scheduler.step(val_metrics['AUROC'])\n",
        "\n",
        "        # Save best model\n",
        "        if val_metrics['AUROC'] > best_val_auroc:\n",
        "            best_val_auroc = val_metrics['AUROC']\n",
        "            torch.save(model.state_dict(), \"best_multimodal_model.pth\")\n",
        "            print(\"‚úÖ Saved new best model.\")\n",
        "\n",
        "    print(f\"\\nTraining complete. Best Val AUROC: {best_val_auroc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9qtaoxLJiwE"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Test evaluation (multimodal)\n",
        "# -----------------------------\n",
        "def evaluate_test(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_labels, all_preds = [], []\n",
        "\n",
        "    loop = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for images, metadata, labels, _, _ in loop:  # unpack multimodal batch\n",
        "            images, metadata, labels = images.to(device), metadata.to(device), labels.float().to(device)\n",
        "            outputs = model(images, metadata)\n",
        "            preds = torch.sigmoid(outputs)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_preds = np.array(all_preds)\n",
        "    metrics = compute_metrics(all_labels, all_preds)\n",
        "\n",
        "    print(\"\\n=== Test Metrics ===\")\n",
        "    print(f\"AUROC   : {metrics['AUROC']:.4f}\")\n",
        "    print(f\"AUPRC   : {metrics['AUPRC']:.4f}\")\n",
        "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "    print(f\"F1      : {metrics['F1']:.4f}\")\n",
        "    print(f\"Brier   : {metrics['Brier']:.4f}\")\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5kxoGaX59jK"
      },
      "outputs": [],
      "source": [
        "def run_training_multimodal(model, train_loader, val_loader, test_loader, device,\n",
        "                            epochs=10, lr=1e-4, weight_decay=1e-4,\n",
        "                            checkpoint_path=\"best_model.pth\"):\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=2)\n",
        "\n",
        "    best_val_auroc = 0.0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # -----------------------------\n",
        "        # Training\n",
        "        # -----------------------------\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        all_labels, all_preds = [], []\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} [Train]\", leave=False)\n",
        "        for images, metadata, labels, _, _ in loop:  # unpack multimodal batch\n",
        "            images, metadata, labels = images.to(device), metadata.to(device), labels.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images, metadata)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(torch.sigmoid(outputs).detach().cpu().numpy())\n",
        "\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_metrics = compute_metrics(np.array(all_labels), np.array(all_preds))\n",
        "\n",
        "        # -----------------------------\n",
        "        # Validation\n",
        "        # -----------------------------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        all_labels, all_preds = [], []\n",
        "\n",
        "        loop = tqdm(val_loader, desc=f\"Epoch {epoch}/{epochs} [Val]\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for images, metadata, labels, _, _ in loop:\n",
        "                images, metadata, labels = images.to(device), metadata.to(device), labels.float().to(device)\n",
        "                outputs = model(images, metadata)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "\n",
        "                loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_metrics = compute_metrics(np.array(all_labels), np.array(all_preds))\n",
        "\n",
        "        print(f\"Epoch {epoch}/{epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
        "              f\"Val AUROC: {val_metrics['AUROC']:.4f}\")\n",
        "\n",
        "        # -----------------------------\n",
        "        # Scheduler & Checkpoint\n",
        "        # -----------------------------\n",
        "        scheduler.step(val_metrics['AUROC'])\n",
        "\n",
        "        if val_metrics['AUROC'] > best_val_auroc:\n",
        "            best_val_auroc = val_metrics['AUROC']\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(f\"‚úÖ Saved best model at epoch {epoch} (Val AUROC: {best_val_auroc:.4f})\")\n",
        "\n",
        "    # -----------------------------\n",
        "    # Load best model & test\n",
        "    # -----------------------------\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "    model.to(device)\n",
        "    print(\"\\n=== Evaluating on Test Set ===\")\n",
        "    test_metrics = evaluate_test(model, test_loader, device)\n",
        "\n",
        "    return model, train_metrics, val_metrics, test_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkSlo_j76L72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3488b58e-5d85-43f7-c65a-65a65d59a990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Train Loss: 0.9956 | Val Loss: 0.5858 | Val AUROC: 0.7939\n",
            "‚úÖ Saved best model at epoch 1 (Val AUROC: 0.7939)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 | Train Loss: 0.8765 | Val Loss: 0.5407 | Val AUROC: 0.8017\n",
            "‚úÖ Saved best model at epoch 2 (Val AUROC: 0.8017)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 | Train Loss: 0.7790 | Val Loss: 0.4652 | Val AUROC: 0.8136\n",
            "‚úÖ Saved best model at epoch 3 (Val AUROC: 0.8136)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 | Train Loss: 0.7408 | Val Loss: 0.4542 | Val AUROC: 0.8164\n",
            "‚úÖ Saved best model at epoch 4 (Val AUROC: 0.8164)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 | Train Loss: 0.7108 | Val Loss: 0.4468 | Val AUROC: 0.8186\n",
            "‚úÖ Saved best model at epoch 5 (Val AUROC: 0.8186)\n",
            "\n",
            "=== Evaluating on Test Set ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Test Metrics ===\n",
            "AUROC   : 0.7181\n",
            "AUPRC   : 0.3267\n",
            "Accuracy: 0.9040\n",
            "F1      : 0.1579\n",
            "Brier   : 0.0673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "model = StudyLevelMultimodalNet(backbone=\"resnet50\", pretrained=True).to(device)\n",
        "trained_model, train_metrics, val_metrics, test_metrics = run_training_multimodal(\n",
        "    model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    test_loader=test_loader,\n",
        "    device=device,\n",
        "    epochs=5,\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-4,\n",
        "    checkpoint_path=\"best_multimodal_model.pth\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zs_UnCW6uAl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}